{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDN1wDBkhIpL"
      },
      "outputs": [],
      "source": [
        "# NOTE:\n",
        "# This installation cell is required only when running the notebook in cloud\n",
        "# environments such as Google Colab. Local environments with pre-installed\n",
        "# dependencies can safely skip this step.\n",
        "!pip install -q kaggle xgboost openpyxl\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# SECTION 1: Imports & Globals (with Kaggle)\n",
        "# =========================\n",
        "import os, glob, random, json, shutil, zipfile, subprocess, sys, time\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Dict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms, models\n",
        "from torchvision.models import MobileNet_V2_Weights\n",
        "\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, roc_auc_score, confusion_matrix, RocCurveDisplay\n",
        ")\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns  # optional; keep only if used later\n",
        "\n",
        "# ==== General settings ====\n",
        "SEED = 42\n",
        "FIXED_SEED = True\n",
        "N_RUNS = 5\n",
        "TEST_SIZE = 0.30\n",
        "\n",
        "NUM_FRAMES_PER_VIDEO = 64\n",
        "FRAME_SIZE = 224\n",
        "BATCH_SIZE = 128\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# IMPORTANT (Reviewer-safety note):\n",
        "# Training supervision is VIDEO-LEVEL only (Normal/Anomalous per video).\n",
        "# No frame-level annotations are used for training. Any segment/frame scores\n",
        "# (if computed later) are inference-based and must not be interpreted as\n",
        "# supervised temporal localization.\n",
        "\n",
        "# ==== Paths ====\n",
        "# Colab default root is /content. For local runs you can set:\n",
        "# export WSAD_ROOT=/path/to/your/workdir\n",
        "ROOT_DIR = os.environ.get(\"WSAD_ROOT\", \"/content\")\n",
        "\n",
        "DATA_DIR     = os.path.join(ROOT_DIR, \"ucf_crime\")   # contains Normal/ and Anomaly/\n",
        "FRAMES_DIR   = os.path.join(ROOT_DIR, \"frames\")\n",
        "FEATURES_DIR = os.path.join(ROOT_DIR, \"features\")\n",
        "RESULTS_DIR  = os.path.join(ROOT_DIR, \"results\")\n",
        "CACHE_DIR    = os.path.join(ROOT_DIR, \"cache\")\n",
        "\n",
        "for d in [DATA_DIR, FRAMES_DIR, FEATURES_DIR, RESULTS_DIR, CACHE_DIR]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "# ==== Kaggle config ====\n",
        "# Update this to your Kaggle dataset slug (owner/dataset-slug)\n",
        "KAGGLE_DATASET   = \"owner/ucf-crime-videos\"  # <-- replace with the correct slug\n",
        "KAGGLE_DEST      = DATA_DIR\n",
        "KAGGLE_JSON_PATH = \"/root/.kaggle/kaggle.json\"  # default path for Kaggle API token (Colab)\n",
        "\n",
        "# ==== Experiments ====\n",
        "EXPERIMENTS = [\n",
        "    {\"name\": \"baseline\",         \"context\": False, \"aug\": False, \"mmd\": False, \"attention\": False},\n",
        "    {\"name\": \"context\",          \"context\": True,  \"aug\": False, \"mmd\": False, \"attention\": False},\n",
        "    {\"name\": \"aug\",              \"context\": False, \"aug\": True,  \"mmd\": False, \"attention\": False},\n",
        "    {\"name\": \"context_aug_mmd\",  \"context\": True,  \"aug\": True,  \"mmd\": True,  \"attention\": False},\n",
        "    {\"name\": \"attention_mil\",    \"context\": False, \"aug\": False, \"mmd\": False, \"attention\": True},\n",
        "]\n",
        "# Note: 'attention_mil' is an experimental extension; the core baseline here is mean-pooling MIL.\n",
        "\n",
        "print(f\"Using DEVICE = {DEVICE}\")\n",
        "print(f\"ROOT_DIR = {ROOT_DIR}\")\n"
      ],
      "metadata": {
        "id": "eqPaK0z-hxgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# SECTION 2: Reproducibility helpers\n",
        "# =========================\n",
        "# Ensures reproducibility across runs (CPU/GPU, NumPy, PyTorch)\n",
        "def set_seed(seed: int = 42):\n",
        "    import os, random\n",
        "    import numpy as np\n",
        "    import torch\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "\n",
        "set_seed(SEED)\n"
      ],
      "metadata": {
        "id": "Srs3_qAiia4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# SECTION 3: Kaggle API helpers + Download (robust)\n",
        "# =========================\n",
        "# SECURITY NOTE:\n",
        "# Do NOT commit kaggle.json to GitHub. Keep it local/Colab only.\n",
        "\n",
        "import subprocess, shlex\n",
        "\n",
        "def _in_colab():\n",
        "    try:\n",
        "        import google.colab  # noqa: F401\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def ensure_kaggle_api(kaggle_json_path=KAGGLE_JSON_PATH):\n",
        "    \"\"\"\n",
        "    Ensures kaggle.json exists and is configured correctly.\n",
        "    - Colab: allows one-time upload if missing.\n",
        "    - Local: place kaggle.json at the provided path and rerun.\n",
        "    \"\"\"\n",
        "    # Allow overriding via environment variable (useful for local runs)\n",
        "    kaggle_json_path = os.environ.get(\"KAGGLE_JSON\", kaggle_json_path)\n",
        "\n",
        "    if not os.path.exists(kaggle_json_path):\n",
        "        if _in_colab():\n",
        "            from google.colab import files\n",
        "            print(\"[KAGGLE] kaggle.json not found. Please upload it nowâ€¦\")\n",
        "            files.upload()\n",
        "            if not os.path.exists(\"kaggle.json\"):\n",
        "                raise FileNotFoundError(\"Upload cancelled. Please provide kaggle.json.\")\n",
        "            os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "            shutil.move(\"kaggle.json\", \"/root/.kaggle/kaggle.json\")\n",
        "            kaggle_json_path = \"/root/.kaggle/kaggle.json\"\n",
        "        else:\n",
        "            raise FileNotFoundError(\n",
        "                f\"kaggle.json not found at {kaggle_json_path}. \"\n",
        "                \"Set env KAGGLE_JSON=/path/to/kaggle.json or place it at KAGGLE_JSON_PATH.\"\n",
        "            )\n",
        "\n",
        "    # Default Kaggle config path (works in Colab/Linux)\n",
        "    os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "    if kaggle_json_path != \"/root/.kaggle/kaggle.json\":\n",
        "        shutil.copy(kaggle_json_path, \"/root/.kaggle/kaggle.json\")\n",
        "    os.chmod(\"/root/.kaggle/kaggle.json\", 0o600)\n",
        "    print(\"[KAGGLE] API is configured.\")\n",
        "\n",
        "def _run(cmd: str):\n",
        "    \"\"\"Runs a shell command and prints output.\"\"\"\n",
        "    print(f\"$ {cmd}\")\n",
        "    result = subprocess.run(\n",
        "        shlex.split(cmd),\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        text=True\n",
        "    )\n",
        "    print(result.stdout)\n",
        "    if result.returncode != 0:\n",
        "        raise RuntimeError(f\"Command failed: {cmd}\")\n",
        "\n",
        "def kaggle_list_files(dataset_slug=KAGGLE_DATASET):\n",
        "    \"\"\"Lists dataset files on Kaggle (diagnostic).\"\"\"\n",
        "    _run(f\"kaggle datasets files -d {dataset_slug}\")\n",
        "\n",
        "def kaggle_download_dataset(dataset_slug=KAGGLE_DATASET, dest_dir=KAGGLE_DEST, force=False):\n",
        "    \"\"\"\n",
        "    Downloads dataset contents into dest_dir.\n",
        "    If force=True, re-downloads even if files exist.\n",
        "    \"\"\"\n",
        "    os.makedirs(dest_dir, exist_ok=True)\n",
        "    cmd = f\"kaggle datasets download -d {dataset_slug} -p {dest_dir}\"\n",
        "    if force:\n",
        "        cmd += \" --force\"\n",
        "    _run(cmd)\n",
        "\n",
        "    # Unzip any downloaded zip files\n",
        "    zips = glob.glob(os.path.join(dest_dir, \"*.zip\"))\n",
        "    if not zips:\n",
        "        print(\"[WARN] No zip files found after download â€” maybe already unzipped.\")\n",
        "    for z in zips:\n",
        "        print(f\"[KAGGLE] Unzipping: {os.path.basename(z)}\")\n",
        "        with zipfile.ZipFile(z, \"r\") as zf:\n",
        "            zf.extractall(dest_dir)\n",
        "    print(\"[KAGGLE] Download & unzip complete.\")\n",
        "\n",
        "def normalize_ucf_structure(root=DATA_DIR):\n",
        "    \"\"\"\n",
        "    Heuristic structure normalization:\n",
        "      DATA_DIR/Normal/*.mp4\n",
        "      DATA_DIR/Anomaly/*.mp4\n",
        "    NOTE: This relies on path/name keywords (normal/anomaly). Verify results.\n",
        "    \"\"\"\n",
        "    mp4s = glob.glob(os.path.join(root, \"**\", \"*.mp4\"), recursive=True)\n",
        "    if not mp4s:\n",
        "        print(\"[WARN] No .mp4 files found yet in DATA_DIR.\")\n",
        "        return\n",
        "\n",
        "    norm_dir = os.path.join(root, \"Normal\")\n",
        "    anom_dir = os.path.join(root, \"Anomaly\")\n",
        "    os.makedirs(norm_dir, exist_ok=True)\n",
        "    os.makedirs(anom_dir, exist_ok=True)\n",
        "\n",
        "    moved = 0\n",
        "    for p in mp4s:\n",
        "        base = os.path.basename(p)\n",
        "        low = p.lower()\n",
        "        if \"normal\" in low:\n",
        "            dst = os.path.join(norm_dir, base)\n",
        "        elif \"anomaly\" in low or \"abnormal\" in low or \"anomal\" in low:\n",
        "            dst = os.path.join(anom_dir, base)\n",
        "        else:\n",
        "            continue\n",
        "        if os.path.abspath(p) != os.path.abspath(dst):\n",
        "            os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
        "            shutil.move(p, dst)\n",
        "            moved += 1\n",
        "\n",
        "    # Cleanup empty folders\n",
        "    for dirpath, dirnames, filenames in os.walk(root, topdown=False):\n",
        "        if dirpath in [norm_dir, anom_dir, root]:\n",
        "            continue\n",
        "        if not os.listdir(dirpath):\n",
        "            shutil.rmtree(dirpath, ignore_errors=True)\n",
        "\n",
        "    print(f\"[STRUCTURE] Moved {moved} files into Normal/ and Anomaly/.\")\n",
        "\n",
        "def ensure_ucf_from_kaggle(force=False, list_files=False):\n",
        "    \"\"\"\n",
        "    Full workflow: configure API -> (optional) list files -> download -> unzip -> normalize structure.\n",
        "    \"\"\"\n",
        "    ensure_kaggle_api()\n",
        "    if list_files:\n",
        "        kaggle_list_files()\n",
        "    kaggle_download_dataset(force=force)\n",
        "    normalize_ucf_structure(DATA_DIR)\n",
        "    n_normal = len(glob.glob(os.path.join(DATA_DIR, \"Normal\", \"*.mp4\")))\n",
        "    n_anom   = len(glob.glob(os.path.join(DATA_DIR, \"Anomaly\", \"*.mp4\")))\n",
        "    print(f\"[READY] Normal: {n_normal} | Anomaly: {n_anom} (root: {DATA_DIR})\")\n"
      ],
      "metadata": {
        "id": "3c9Qit_yiwqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# SECTION 3.1 â€” Kaggle API (Colab-simple)\n",
        "# =========================\n",
        "# SECURITY NOTE:\n",
        "# Do NOT commit kaggle.json to GitHub. Keep it local/Colab only.\n",
        "\n",
        "def setup_kaggle_colab_simple():\n",
        "    \"\"\"Colab-only helper to upload kaggle.json and configure Kaggle API.\"\"\"\n",
        "    try:\n",
        "        from google.colab import files  # type: ignore\n",
        "    except Exception:\n",
        "        print(\"[INFO] Not running in Colab. Skip this cell and configure Kaggle API locally.\")\n",
        "        print(\"       Option 1: place kaggle.json at /root/.kaggle/kaggle.json (Linux/Colab)\")\n",
        "        print(\"       Option 2: use ensure_kaggle_api() from SECTION 3 (robust)\")\n",
        "        return\n",
        "\n",
        "    import os, shutil\n",
        "\n",
        "    print(\"â¬†ï¸ Please upload kaggle.json â€¦\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if \"kaggle.json\" not in uploaded:\n",
        "        raise FileNotFoundError(\"kaggle.json was not uploaded. Please retry.\")\n",
        "\n",
        "    os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "    shutil.move(\"kaggle.json\", \"/root/.kaggle/kaggle.json\")\n",
        "    os.chmod(\"/root/.kaggle/kaggle.json\", 0o600)\n",
        "\n",
        "    print(\"âœ… Kaggle API configured for Colab.\")\n",
        "\n",
        "# Run only when needed (Colab)\n",
        "setup_kaggle_colab_simple()\n"
      ],
      "metadata": {
        "id": "NPuBTtOZjHZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# SECTION 3.2 â€” Download + Unzip + Normalize (Colab-simple)\n",
        "# =========================\n",
        "# NOTE (Dataset / Licensing):\n",
        "# UCF-Crime is not distributed with this repository. Downloading datasets from Kaggle\n",
        "# depends on the dataset uploader's terms and may not reflect the original dataset license.\n",
        "# Use at your own responsibility and ensure compliance with applicable terms.\n",
        "\n",
        "import os, glob, zipfile, shutil\n",
        "\n",
        "# 1) Dataset slug (override via environment variable if needed)\n",
        "KAGGLE_DATASET = os.environ.get(\"KAGGLE_DATASET\", \"minhajuddinmeraj/anomalydetectiondatasetucf\")\n",
        "DATA_DIR       = os.environ.get(\"WSAD_DATA_DIR\", \"/content/ucf_crime\")\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "# 2) (Optional) list available files (diagnostic)\n",
        "print(\"[INFO] Listing Kaggle dataset files (optional)...\")\n",
        "!kaggle datasets files -d $KAGGLE_DATASET\n",
        "\n",
        "# 3) Download dataset\n",
        "print(f\"ðŸ“¥ Downloading {KAGGLE_DATASET} â†’ {DATA_DIR}\")\n",
        "!kaggle datasets download -d $KAGGLE_DATASET -p $DATA_DIR --force\n",
        "\n",
        "# 4) Unzip any ZIP files\n",
        "zips = glob.glob(os.path.join(DATA_DIR, \"*.zip\"))\n",
        "if not zips:\n",
        "    print(\"[WARN] No ZIP files found (maybe already unzipped).\")\n",
        "else:\n",
        "    for z in zips:\n",
        "        print(f\"ðŸ—œï¸ Unzipping: {os.path.basename(z)}\")\n",
        "        with zipfile.ZipFile(z, \"r\") as zf:\n",
        "            zf.extractall(DATA_DIR)\n",
        "\n",
        "# 5) Normalize structure into Normal/ and Anomaly/\n",
        "def normalize_ucf_structure(root=DATA_DIR):\n",
        "    \"\"\"\n",
        "    Organizes mp4 files into:\n",
        "      root/Normal/*.mp4\n",
        "      root/Anomaly/*.mp4\n",
        "\n",
        "    NOTE: This is a heuristic that assumes any path/name containing 'normal'\n",
        "    belongs to Normal, and everything else belongs to Anomaly. Verify the dataset\n",
        "    structure and adjust if needed.\n",
        "    \"\"\"\n",
        "    norm_dir = os.path.join(root, \"Normal\")\n",
        "    anom_dir = os.path.join(root, \"Anomaly\")\n",
        "    os.makedirs(norm_dir, exist_ok=True)\n",
        "    os.makedirs(anom_dir, exist_ok=True)\n",
        "\n",
        "    mp4s = glob.glob(os.path.join(root, \"**\", \"*.mp4\"), recursive=True)\n",
        "    if not mp4s:\n",
        "        print(\"[WARN] No .mp4 files found. Please inspect the extracted contents.\")\n",
        "        return\n",
        "\n",
        "    moved = 0\n",
        "    for p in mp4s:\n",
        "        base = os.path.basename(p)\n",
        "        low  = p.lower()\n",
        "        if \"normal\" in low:\n",
        "            dst = os.path.join(norm_dir, base)\n",
        "        else:\n",
        "            dst = os.path.join(anom_dir, base)\n",
        "        if os.path.abspath(p) != os.path.abspath(dst):\n",
        "            shutil.move(p, dst)\n",
        "            moved += 1\n",
        "\n",
        "    # Cleanup empty folders\n",
        "    for dirpath, _, __ in os.walk(root, topdown=False):\n",
        "        if dirpath in [norm_dir, anom_dir, root]:\n",
        "            continue\n",
        "        if not os.listdir(dirpath):\n",
        "            shutil.rmtree(dirpath, ignore_errors=True)\n",
        "\n",
        "    print(f\"ðŸ“ Organized: moved {moved} files â†’ Normal/ & Anomaly/\")\n",
        "\n",
        "normalize_ucf_structure(DATA_DIR)\n",
        "\n",
        "# 6) Final counts\n",
        "n_normal = len(glob.glob(os.path.join(DATA_DIR, \"Normal\", \"*.mp4\")))\n",
        "n_anom   = len(glob.glob(os.path.join(DATA_DIR, \"Anomaly\", \"*.mp4\")))\n",
        "print(f\"âœ… READY â€” Normal: {n_normal} | Anomaly: {n_anom} | root: {DATA_DIR}\")\n"
      ],
      "metadata": {
        "id": "h2bM_5iBjiZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# SECTION 4 â€” Normalize structure & scan videos\n",
        "# =========================\n",
        "import os, glob, shutil\n",
        "import pandas as pd\n",
        "\n",
        "# NOTE:\n",
        "# This section builds VIDEO-LEVEL metadata (one label per video).\n",
        "# Ensure DATA_DIR is defined in SECTION 1 (do not redefine it here).\n",
        "\n",
        "LABEL_MAP = {\"Normal\": 0, \"Anomaly\": 1}\n",
        "\n",
        "def normalize_ucf_structure(root: str = DATA_DIR, dry_run: bool = False) -> None:\n",
        "    \"\"\"\n",
        "    Ensures the standard structure:\n",
        "      root/Normal/*.mp4\n",
        "      root/Anomaly/*.mp4\n",
        "\n",
        "    NOTE (Heuristic):\n",
        "    This normalization uses a simple rule:\n",
        "      if 'normal' in file path/name -> Normal\n",
        "      else -> Anomaly\n",
        "    Verify the resulting folders if you use a different dataset packaging.\n",
        "    \"\"\"\n",
        "    norm_dir = os.path.join(root, \"Normal\")\n",
        "    anom_dir = os.path.join(root, \"Anomaly\")\n",
        "    os.makedirs(norm_dir, exist_ok=True)\n",
        "    os.makedirs(anom_dir, exist_ok=True)\n",
        "\n",
        "    mp4s = glob.glob(os.path.join(root, \"**\", \"*.mp4\"), recursive=True)\n",
        "    if not mp4s:\n",
        "        print(\"[WARN] No .mp4 files found. Ensure download/unzip is completed.\")\n",
        "        return\n",
        "\n",
        "    moved = 0\n",
        "    planned = 0\n",
        "    for p in mp4s:\n",
        "        base = os.path.basename(p)\n",
        "        low  = p.lower()\n",
        "\n",
        "        dst = os.path.join(norm_dir, base) if \"normal\" in low else os.path.join(anom_dir, base)\n",
        "\n",
        "        if os.path.abspath(p) != os.path.abspath(dst):\n",
        "            planned += 1\n",
        "            if dry_run:\n",
        "                continue\n",
        "            shutil.move(p, dst)\n",
        "            moved += 1\n",
        "\n",
        "    # Cleanup empty folders\n",
        "    if not dry_run:\n",
        "        for dirpath, _, __ in os.walk(root, topdown=False):\n",
        "            if dirpath in {root, norm_dir, anom_dir}:\n",
        "                continue\n",
        "            if not os.listdir(dirpath):\n",
        "                shutil.rmtree(dirpath, ignore_errors=True)\n",
        "\n",
        "    if dry_run:\n",
        "        print(f\"[DRY RUN] Would move {planned} files into Normal/ & Anomaly/.\")\n",
        "    else:\n",
        "        print(f\"ðŸ“ Organized: moved {moved} files â†’ Normal/ & Anomaly/\")\n",
        "\n",
        "def scan_videos(data_dir: str = DATA_DIR) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Builds a VIDEO-LEVEL metadata DataFrame with:\n",
        "      video_id, label, path, cls\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for cls in [\"Normal\", \"Anomaly\"]:\n",
        "        cls_dir = os.path.join(data_dir, cls)\n",
        "        if not os.path.isdir(cls_dir):\n",
        "            print(f\"[WARN] Missing class dir: {cls_dir}\")\n",
        "            continue\n",
        "\n",
        "        for p in glob.glob(os.path.join(cls_dir, \"*.mp4\")):\n",
        "            vid = os.path.splitext(os.path.basename(p))[0]\n",
        "            rows.append({\n",
        "                \"video_id\": vid,\n",
        "                \"label\": LABEL_MAP[cls],\n",
        "                \"path\": p,\n",
        "                \"cls\": cls\n",
        "            })\n",
        "\n",
        "    meta = pd.DataFrame(rows)\n",
        "    if meta.empty:\n",
        "        print(\"[WARN] No videos detected after normalization.\")\n",
        "    else:\n",
        "        n_norm = int((meta[\"label\"] == 0).sum())\n",
        "        n_anom = int((meta[\"label\"] == 1).sum())\n",
        "        print(f\"âœ… READY â€” Videos: {len(meta)} | Normal: {n_norm} | Anomaly: {n_anom}\")\n",
        "    return meta\n",
        "\n",
        "# === Run SECTION 4 ===\n",
        "normalize_ucf_structure(DATA_DIR, dry_run=False)\n",
        "meta = scan_videos(DATA_DIR)\n",
        "assert not meta.empty, \"No videos detected after normalization.\"\n"
      ],
      "metadata": {
        "id": "LZdNmK6Fj5YG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# SECTION 5.1 â€” Frame Extraction helpers\n",
        "# =========================\n",
        "import os, glob, time\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Optional\n",
        "\n",
        "# Depends on earlier sections:\n",
        "# DATA_DIR, FRAMES_DIR, NUM_FRAMES_PER_VIDEO\n",
        "\n",
        "os.makedirs(FRAMES_DIR, exist_ok=True)\n",
        "\n",
        "# NOTE: Frames are sampled uniformly across the video for feature extraction.\n",
        "# This is not intended for precise temporal anomaly localization.\n",
        "\n",
        "def extract_frames_for_video(video_path: str, out_dir: str, n_frames: int = NUM_FRAMES_PER_VIDEO) -> int:\n",
        "    \"\"\"\n",
        "    Extracts n_frames uniformly across the video and saves JPGs to out_dir.\n",
        "    Returns the number of newly saved images (does not recount existing ones).\n",
        "    \"\"\"\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        cap.release()\n",
        "        return 0\n",
        "\n",
        "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    if total <= 0:\n",
        "        cap.release()\n",
        "        return 0\n",
        "\n",
        "    existing = sorted(glob.glob(os.path.join(out_dir, \"*.jpg\")))\n",
        "    if len(existing) >= n_frames:\n",
        "        cap.release()\n",
        "        return 0\n",
        "\n",
        "    idxs = np.linspace(0, total - 1, num=n_frames, dtype=int)\n",
        "    saved = 0\n",
        "    for i, fi in enumerate(idxs):\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(fi))\n",
        "        ok, frame = cap.read()\n",
        "        if not ok:\n",
        "            continue\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        out_path = os.path.join(out_dir, f\"{i:04d}.jpg\")\n",
        "        Image.fromarray(frame_rgb).save(out_path, quality=92)\n",
        "        saved += 1\n",
        "\n",
        "    cap.release()\n",
        "    return saved\n",
        "\n",
        "def ensure_frames(\n",
        "    meta: pd.DataFrame,\n",
        "    n_frames: int = NUM_FRAMES_PER_VIDEO,\n",
        "    limit_per_class: Optional[int] = None\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Extracts frames for each video in `meta` if needed.\n",
        "    limit_per_class: e.g., 2 to run only first N videos per class for quick tests.\n",
        "    \"\"\"\n",
        "    stats = {\"videos_processed\": 0, \"new_images_saved\": 0, \"normal_done\": 0, \"anomaly_done\": 0}\n",
        "    class_count = {\"Normal\": 0, \"Anomaly\": 0}\n",
        "\n",
        "    t0 = time.time()\n",
        "    for _, r in meta.iterrows():\n",
        "        cls = r[\"cls\"]\n",
        "        if limit_per_class is not None and class_count[cls] >= limit_per_class:\n",
        "            continue\n",
        "\n",
        "        vid_dir = os.path.join(FRAMES_DIR, cls, r[\"video_id\"])\n",
        "        saved_now = extract_frames_for_video(r[\"path\"], vid_dir, n_frames=n_frames)\n",
        "\n",
        "        stats[\"videos_processed\"] += 1\n",
        "        stats[\"new_images_saved\"] += saved_now\n",
        "        class_count[cls] += 1\n",
        "\n",
        "        if cls == \"Normal\":\n",
        "            stats[\"normal_done\"] += 1\n",
        "        else:\n",
        "            stats[\"anomaly_done\"] += 1\n",
        "\n",
        "    dt = time.time() - t0\n",
        "    print(\n",
        "        f\"âœ… ensure_frames â†’ videos: {stats['videos_processed']}, new_jpg: {stats['new_images_saved']}, \"\n",
        "        f\"Normal:{stats['normal_done']}, Anomaly:{stats['anomaly_done']} | time: {dt:.1f}s\"\n",
        "    )\n",
        "    return stats\n"
      ],
      "metadata": {
        "id": "LUzOzVmUkMCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# SECTION 5.2 â€” Run full frame extraction (no limits)\n",
        "# =========================\n",
        "import glob\n",
        "\n",
        "assert 'meta' in globals() and not meta.empty, \"meta ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©: Ø´ØºÙ‘Ù„ SECTION 4 Ø£ÙˆÙ„Ø§Ù‹.\"\n",
        "\n",
        "# Safety switch (recommended for GitHub users)\n",
        "RUN_FULL_EXTRACTION = True  # set to False for quick tests\n",
        "\n",
        "if RUN_FULL_EXTRACTION:\n",
        "    _ = ensure_frames(meta, n_frames=NUM_FRAMES_PER_VIDEO, limit_per_class=None)\n",
        "\n",
        "    n_frames_normal  = len(glob.glob(os.path.join(FRAMES_DIR, \"Normal\",  \"*\", \"*.jpg\")))\n",
        "    n_frames_anomaly = len(glob.glob(os.path.join(FRAMES_DIR, \"Anomaly\", \"*\", \"*.jpg\")))\n",
        "    print(f\"âœ… Frames saved â†’ Normal:{n_frames_normal} | Anomaly:{n_frames_anomaly} | root:{FRAMES_DIR}\")\n",
        "else:\n",
        "    print(\"[SKIP] Full frame extraction is disabled. Set RUN_FULL_EXTRACTION=True to run.\")\n"
      ],
      "metadata": {
        "id": "WJSkY7BlkihU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# SECTION 6 â€” Transforms (BASE / AUG)\n",
        "# =========================\n",
        "from torchvision import transforms\n",
        "\n",
        "# NOTE:\n",
        "# FRAME_SIZE is defined in SECTION 1. Do not redefine it here to avoid inconsistencies.\n",
        "\n",
        "BASE_TRANSFORM = transforms.Compose([\n",
        "    transforms.Resize((FRAME_SIZE, FRAME_SIZE)),\n",
        "    transforms.ToTensor(),  # [0..1]\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std =[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Used only when the experiment configuration enables augmentation (aug=True).\n",
        "AUG_TRANSFORM = transforms.Compose([\n",
        "    transforms.Resize((FRAME_SIZE, FRAME_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomApply([\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2,\n",
        "                               saturation=0.2, hue=0.05)\n",
        "    ], p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std =[0.229, 0.224, 0.225]),\n",
        "])\n"
      ],
      "metadata": {
        "id": "PbhJVTTNkyoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# SECTION 7 â€” Feature Extraction (MobileNetV2) + Safe Cache\n",
        "# =========================\n",
        "import os, glob, numpy as np, pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "from torchvision.models import MobileNet_V2_Weights\n",
        "from typing import Optional, Set, Dict\n",
        "\n",
        "# Required from earlier sections:\n",
        "# FRAMES_DIR, FEATURES_DIR, DEVICE, BATCH_SIZE, BASE_TRANSFORM, AUG_TRANSFORM\n",
        "\n",
        "os.makedirs(FEATURES_DIR, exist_ok=True)\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 7.1 â€” MobileNetV2 as 1280D feature extractor\n",
        "# -------------------------------------------------------------\n",
        "_mobilenet = models.mobilenet_v2(weights=MobileNet_V2_Weights.DEFAULT).features\n",
        "FEATURE_EXTRACTOR = nn.Sequential(\n",
        "    _mobilenet,\n",
        "    nn.AdaptiveAvgPool2d((1, 1))\n",
        ").to(DEVICE).eval()\n",
        "\n",
        "for p in FEATURE_EXTRACTOR.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 7.2 â€” Safe batch inference (with fallback on CUDA OOM)\n",
        "# -------------------------------------------------------------\n",
        "@torch.no_grad()\n",
        "def _infer_batch(img_tensors, batch_size: Optional[int] = None) -> np.ndarray:\n",
        "    if batch_size is None:\n",
        "        batch_size = len(img_tensors)\n",
        "    feats_list, i = [], 0\n",
        "\n",
        "    while i < len(img_tensors):\n",
        "        chunk = img_tensors[i:i+batch_size]\n",
        "        try:\n",
        "            xb = torch.stack(chunk, dim=0).to(DEVICE)\n",
        "            fb = FEATURE_EXTRACTOR(xb).reshape(len(chunk), -1)\n",
        "            feats_list.append(fb.cpu().numpy().astype(np.float32))\n",
        "            i += batch_size\n",
        "        except RuntimeError as e:\n",
        "            # Only attempt batch reduction on CUDA OOM\n",
        "            if (\"CUDA\" in str(e) or \"out of memory\" in str(e).lower()) and (DEVICE.type == \"cuda\") and batch_size > 1:\n",
        "                torch.cuda.empty_cache()\n",
        "                batch_size = max(1, batch_size // 2)\n",
        "                continue\n",
        "            raise\n",
        "\n",
        "    return np.concatenate(feats_list, axis=0) if feats_list else np.empty((0, 1280), np.float32)\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 7.3 â€” Context features (global mean/std per frame)\n",
        "# -------------------------------------------------------------\n",
        "def _context_feat(pil_img: Image.Image) -> np.ndarray:\n",
        "    arr = np.asarray(pil_img).astype(np.float32) / 255.0\n",
        "    return np.array([arr.mean(), arr.std()], dtype=np.float32)\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 7.4 â€” Extract features for a full video (with optional context)\n",
        "# -------------------------------------------------------------\n",
        "def extract_video_features(frame_paths: list, transform, add_context: bool = False) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Converts a list of frame paths to features of shape (num_frames, D)\n",
        "    where D = 1280 (or 1282 if add_context=True).\n",
        "    \"\"\"\n",
        "    feats, batch_imgs, pending_ctx = [], [], []\n",
        "\n",
        "    for p in frame_paths:\n",
        "        try:\n",
        "            with Image.open(p) as img:\n",
        "                img = img.convert(\"RGB\")\n",
        "                x = transform(img)\n",
        "                batch_imgs.append(x)\n",
        "                if add_context:\n",
        "                    pending_ctx.append(_context_feat(img))\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "        if len(batch_imgs) == BATCH_SIZE:\n",
        "            fb = _infer_batch(batch_imgs)\n",
        "            if add_context:\n",
        "                fb = np.hstack([fb, np.asarray(pending_ctx, np.float32)])\n",
        "            feats.append(fb)\n",
        "            batch_imgs, pending_ctx = [], []\n",
        "\n",
        "    if batch_imgs:\n",
        "        fb = _infer_batch(batch_imgs)\n",
        "        if add_context:\n",
        "            fb = np.hstack([fb, np.asarray(pending_ctx, np.float32)])\n",
        "        feats.append(fb)\n",
        "\n",
        "    if not feats:\n",
        "        D = 1282 if add_context else 1280\n",
        "        return np.empty((0, D), dtype=np.float32)\n",
        "\n",
        "    return np.concatenate(feats, axis=0).astype(np.float32)\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 7.5 â€” Safe feature file path per experiment/run/video\n",
        "# -------------------------------------------------------------\n",
        "def _feature_npz_path(cls: str, video_id: str, add_context: bool, use_aug: bool, run_id: Optional[int]) -> str:\n",
        "    exp_tag = (\"ctx\" if add_context else \"base\") + \"_\" + (\"aug\" if use_aug else \"noaug\")\n",
        "    run_tag = f\"run{run_id}\" if (use_aug and run_id is not None) else \"run0\"\n",
        "    out_dir = os.path.join(FEATURES_DIR, exp_tag, run_tag, cls)\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    return os.path.join(out_dir, f\"{video_id}.npz\")\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 7.6 â€” Build safe feature cache (no leakage)\n",
        "# -------------------------------------------------------------\n",
        "def build_feature_cache_for_split(\n",
        "    frames_df: pd.DataFrame,                 # columns: video_id, cls\n",
        "    add_context: bool,\n",
        "    train_only_aug: bool,\n",
        "    train_video_ids: Optional[Set[str]],\n",
        "    run_id: int = 0,\n",
        ") -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Builds a safe feature cache:\n",
        "      - add_context: appends (mean,std) per frame.\n",
        "      - train_only_aug: applies AUG only to training videos.\n",
        "      - run_id: used to separate cached outputs per run.\n",
        "    \"\"\"\n",
        "    id2npz: Dict[str, str] = {}\n",
        "\n",
        "    for _, r in frames_df.iterrows():\n",
        "        vid, cls = r[\"video_id\"], r[\"cls\"]\n",
        "        frame_paths = sorted(glob.glob(os.path.join(FRAMES_DIR, cls, vid, \"*.jpg\")))\n",
        "        if not frame_paths:\n",
        "            continue\n",
        "\n",
        "        use_aug = bool(train_only_aug and (train_video_ids is not None) and (vid in train_video_ids))\n",
        "        out_npz = _feature_npz_path(cls, vid, add_context=add_context, use_aug=use_aug, run_id=run_id)\n",
        "\n",
        "        if os.path.exists(out_npz):\n",
        "            id2npz[vid] = out_npz\n",
        "            continue\n",
        "\n",
        "        tfm = AUG_TRANSFORM if use_aug else BASE_TRANSFORM\n",
        "        feats = extract_video_features(frame_paths, transform=tfm, add_context=add_context)\n",
        "        label = 0 if cls.lower() == \"normal\" else 1\n",
        "        feat_dim = feats.shape[1] if feats.ndim == 2 and feats.size else (1282 if add_context else 1280)\n",
        "\n",
        "        np.savez_compressed(\n",
        "            out_npz,\n",
        "            features=feats,\n",
        "            video_id=vid,\n",
        "            cls=cls,\n",
        "            label=np.int64(label),\n",
        "            feat_dim=np.int32(feat_dim),\n",
        "            add_context=np.int8(1 if add_context else 0),\n",
        "            used_aug=np.int8(1 if use_aug else 0),\n",
        "            run_id=np.int32(run_id),\n",
        "        )\n",
        "        id2npz[vid] = out_npz\n",
        "\n",
        "    print(f\"âœ… Cached feature files: {len(id2npz)} | context={add_context} | aug_train_only={train_only_aug}\")\n",
        "    return id2npz\n"
      ],
      "metadata": {
        "id": "Nys-BS8zlkYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Smoke Test: build base_noaug/run0 cache for videos that have extracted frames ===\n",
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "assert 'meta' in globals() and not meta.empty, \"Ø´ØºÙ‘Ù„ Section 4 Ø£ÙˆÙ„Ù‹Ø§.\"\n",
        "assert 'FRAMES_DIR' in globals() and 'FEATURES_DIR' in globals(), \"Ø´ØºÙ‘Ù„ Section 1 Ø£ÙˆÙ„Ù‹Ø§ (paths).\"\n",
        "\n",
        "frames_rows = []\n",
        "missing = 0\n",
        "\n",
        "for _, r in meta.iterrows():\n",
        "    img_dir = os.path.join(FRAMES_DIR, r[\"cls\"], r[\"video_id\"])\n",
        "    imgs = glob.glob(os.path.join(img_dir, \"*.jpg\"))\n",
        "    if imgs:\n",
        "        frames_rows.append({\"video_id\": r[\"video_id\"], \"cls\": r[\"cls\"]})\n",
        "    else:\n",
        "        missing += 1\n",
        "\n",
        "frames_df = pd.DataFrame(frames_rows).drop_duplicates(subset=[\"video_id\"])\n",
        "print(f\"videos in meta: {len(meta)} | videos with frames: {len(frames_df)} | missing frames: {missing}\")\n",
        "\n",
        "assert not frames_df.empty, (\n",
        "    \"frames_df is empty. Run Section 5.2 to extract frames first, or check FRAMES_DIR path.\"\n",
        ")\n",
        "\n",
        "id2npz_smoke = build_feature_cache_for_split(\n",
        "    frames_df=frames_df,\n",
        "    add_context=False,        # base features only\n",
        "    train_only_aug=False,     # no augmentation\n",
        "    train_video_ids=None,\n",
        "    run_id=0\n",
        ")\n",
        "\n",
        "print(f\"âœ… cached feature files: {len(id2npz_smoke)}\")\n"
      ],
      "metadata": {
        "id": "aO_f8eufl0O-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# SECTION 8 â€” Load bags + mean pooling + audits\n",
        "# =========================\n",
        "import os, numpy as np, pandas as pd\n",
        "from typing import Optional, Set, Tuple, List\n",
        "\n",
        "def load_bags_from_cache(\n",
        "    frames_df: pd.DataFrame,\n",
        "    add_context: bool,\n",
        "    train_only_aug: bool,\n",
        "    train_video_ids: Optional[Set[str]],\n",
        "    run_id: int\n",
        "):\n",
        "    \"\"\"\n",
        "    Loads per-video frame features from cached NPZ files and returns:\n",
        "      - bags: list of arrays (n_frames, D)\n",
        "      - labels: (N,) int64\n",
        "      - vids: list of video_id\n",
        "      - pooled: (N, D) float32 mean-pooled representations\n",
        "    \"\"\"\n",
        "    bags: List[np.ndarray] = []\n",
        "    labels: List[int] = []\n",
        "    vids: List[str] = []\n",
        "    pooled: List[np.ndarray] = []\n",
        "\n",
        "    for _, r in frames_df.iterrows():\n",
        "        vid, cls = r[\"video_id\"], r[\"cls\"]\n",
        "\n",
        "        # Apply AUG only for training videos if enabled\n",
        "        use_aug = bool(train_only_aug and (train_video_ids is not None) and (vid in train_video_ids))\n",
        "\n",
        "        # Use the same path logic as Section 7 to avoid mismatch\n",
        "        npz_path = _feature_npz_path(cls, vid, add_context=add_context, use_aug=use_aug, run_id=run_id)\n",
        "\n",
        "        if not os.path.exists(npz_path):\n",
        "            continue\n",
        "\n",
        "        d = np.load(npz_path, allow_pickle=False)\n",
        "        Xv = d[\"features\"]  # (n_frames, D)\n",
        "\n",
        "        # Skip empty feature arrays (prevents NaNs in pooling)\n",
        "        if Xv.ndim != 2 or Xv.shape[0] == 0:\n",
        "            continue\n",
        "\n",
        "        bags.append(Xv.astype(np.float32))\n",
        "        labels.append(int(d[\"label\"]) if \"label\" in d.files else (0 if cls == \"Normal\" else 1))\n",
        "        vids.append(vid)\n",
        "        pooled.append(Xv.mean(axis=0).astype(np.float32))\n",
        "\n",
        "    if not bags:\n",
        "        raise RuntimeError(\"Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø£ÙŠ Ø­Ù‚Ø§Ø¦Ø¨ Ù…Ù† Ø§Ù„ÙƒØ§Ø´. ØªØ£ÙƒØ¯ Ø£Ù† Section 7 Ù†Ø¬Ø­ ÙˆØ£Ù† Ù…Ù„ÙØ§Øª NPZ Ù…ÙˆØ¬ÙˆØ¯Ø©.\")\n",
        "\n",
        "    return bags, np.array(labels, dtype=np.int64), vids, np.vstack(pooled).astype(np.float32)\n",
        "\n",
        "\n",
        "def audit_no_aug_on_test(\n",
        "    test_indices,\n",
        "    vids: List[str],\n",
        "    add_context: bool,\n",
        "    train_only_aug: bool,\n",
        "    train_ids: Optional[Set[str]],\n",
        "    run_id: int\n",
        ") -> bool:\n",
        "    \"\"\"\n",
        "    Ensures no augmentation was used for test videos.\n",
        "    Reads used_aug from NPZ metadata.\n",
        "    \"\"\"\n",
        "\n",
        "    # If augmentation is not enabled for training, the audit is trivially satisfied.\n",
        "    if not train_only_aug or train_ids is None:\n",
        "        print(\"[AUDIT] train_only_aug disabled or train_ids=None â†’ skipping no-aug-on-test audit.\")\n",
        "        return True\n",
        "\n",
        "    for i in test_indices:\n",
        "        vid = vids[i]\n",
        "\n",
        "        # Test video must not be in training IDs\n",
        "        assert vid not in train_ids, f\"[AUDIT] Split issue: test video {vid} appears in train_ids.\"\n",
        "\n",
        "        found = False\n",
        "        used_aug = 0\n",
        "\n",
        "        # We don't know cls here reliably; search both\n",
        "        for cls_name in (\"Normal\", \"Anomaly\"):\n",
        "            # For augmented train videos: exp_tag ends with _aug and run{run_id}\n",
        "            path_aug = _feature_npz_path(cls_name, vid, add_context=add_context, use_aug=True, run_id=run_id)\n",
        "            # For non-aug videos: exp_tag ends with _noaug and run0 (per Section 7 logic)\n",
        "            path_noaug = _feature_npz_path(cls_name, vid, add_context=add_context, use_aug=False, run_id=run_id)\n",
        "\n",
        "            for p in (path_aug, path_noaug):\n",
        "                if os.path.exists(p):\n",
        "                    d = np.load(p, allow_pickle=False)\n",
        "                    used_aug = int(d[\"used_aug\"]) if \"used_aug\" in d.files else 0\n",
        "                    found = True\n",
        "                    break\n",
        "            if found:\n",
        "                break\n",
        "\n",
        "        assert found, f\"[AUDIT] Feature file not found for video {vid}.\"\n",
        "        assert used_aug == 0, f\"[LEAK] Test video {vid} has used_aug=1 (augmentation leakage).\"\n",
        "\n",
        "    print(\"[AUDIT] Passed: no augmentation applied to test videos.\")\n",
        "    return True\n"
      ],
      "metadata": {
        "id": "euDf4aJLl-hA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# SECTION 9 â€” Attention MIL (optional)\n",
        "# =========================\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class BagsDataset(Dataset):\n",
        "    def __init__(self, bags, labels):\n",
        "        self.bags = bags\n",
        "        self.labels = labels\n",
        "    def __len__(self):\n",
        "        return len(self.bags)\n",
        "    def __getitem__(self, i):\n",
        "        return self.bags[i], int(self.labels[i])\n",
        "\n",
        "def _collate_single(batch):\n",
        "    bag_np, y = batch[0]\n",
        "    bag = torch.tensor(bag_np, dtype=torch.float32)        # (T,D)\n",
        "    y   = torch.tensor([y], dtype=torch.float32)           # (1,)\n",
        "    return bag, y\n",
        "\n",
        "class AttentionMILNet(nn.Module):\n",
        "    def __init__(self, in_dim, hidden=256):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden), nn.Tanh(),\n",
        "            nn.Linear(hidden, 1)\n",
        "        )\n",
        "        self.cls  = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden), nn.ReLU(),\n",
        "            nn.Linear(hidden, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, bag, return_attention: bool = False):\n",
        "        if bag.dim() == 3:\n",
        "            bag = bag.squeeze(0)\n",
        "        w = self.attn(bag)                      # (T,1)\n",
        "        a = torch.softmax(w, dim=0)             # (T,1)\n",
        "        pooled = torch.sum(a * bag, dim=0)      # (D,)\n",
        "        logit  = self.cls(pooled).view(1)       # (1,)\n",
        "        if return_attention:\n",
        "            return logit, a.squeeze(-1)         # (T,)\n",
        "        return logit\n",
        "\n",
        "def evaluate_attention_mil_once(\n",
        "    train_bags, train_y, test_bags, test_y,\n",
        "    epochs=5, lr=1e-3, batch_size=1, seed=42, device=DEVICE\n",
        "):\n",
        "    # basic safety checks\n",
        "    assert len(train_bags) > 0 and train_bags[0].ndim == 2, \"train_bags must be a non-empty list of (T,D) arrays.\"\n",
        "\n",
        "    # seeds\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if device.type == \"cuda\":\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    in_dim = train_bags[0].shape[1]\n",
        "    model  = AttentionMILNet(in_dim).to(device)\n",
        "    opt    = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "    loss_fn= nn.BCEWithLogitsLoss()\n",
        "\n",
        "    tr_ds  = BagsDataset(train_bags, train_y)\n",
        "    te_ds  = BagsDataset(test_bags,  test_y)\n",
        "    tr_dl  = DataLoader(tr_ds, batch_size=1, shuffle=True,  collate_fn=_collate_single)\n",
        "    te_dl  = DataLoader(te_ds, batch_size=1, shuffle=False, collate_fn=_collate_single)\n",
        "\n",
        "    model.train()\n",
        "    for _ in range(epochs):\n",
        "        for xb, yb in tr_dl:\n",
        "            xb = xb.to(device)\n",
        "            yb = yb.to(device)\n",
        "            opt.zero_grad()\n",
        "            logit = model(xb)                  # (1,)\n",
        "            loss = loss_fn(logit, yb)          # shapes match\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "    model.eval()\n",
        "    probs, preds, ys = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in te_dl:\n",
        "            xb = xb.to(device)\n",
        "            logit = model(xb)\n",
        "            p = torch.sigmoid(logit).item()\n",
        "            probs.append(p)\n",
        "            preds.append(1 if p >= 0.5 else 0)\n",
        "            ys.append(int(yb.item()))\n",
        "\n",
        "    from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "    y_true = np.array(ys); y_pred = np.array(preds); y_prob = np.array(probs)\n",
        "    acc = float(accuracy_score(y_true, y_pred))\n",
        "    f1  = float(f1_score(y_true, y_pred))\n",
        "    auc = float('nan') if len(np.unique(y_true)) < 2 else float(roc_auc_score(y_true, y_prob))\n",
        "    return {\"accuracy\": acc, \"f1\": f1, \"auc\": auc, \"y_true\": y_true, \"y_pred\": y_pred, \"y_prob\": y_prob}\n"
      ],
      "metadata": {
        "id": "SMvVbO_2nFdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# SANITY CHECK â€” frames vs cached features\n",
        "# =========================\n",
        "assert \"frames_df\" in globals(), \"frames_df ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© â€” Ø´ØºÙ‘Ù„ Sections 4 Ùˆ5 Ø£ÙˆÙ„Ø§Ù‹.\"\n",
        "assert \"FEATURES_DIR\" in globals(), \"FEATURES_DIR ØºÙŠØ± Ù…Ø¹Ø±Ù‘Ù.\"\n",
        "\n",
        "import glob, os\n",
        "\n",
        "print(\"frames_df rows:\", len(frames_df))\n",
        "npz_files = glob.glob(os.path.join(FEATURES_DIR, \"**\", \"*.npz\"), recursive=True)\n",
        "print(\"NPZ count:\", len(npz_files))\n",
        "\n",
        "if len(npz_files) < len(frames_df):\n",
        "    print(\"âš ï¸ WARNING: Some videos do NOT have cached features yet.\")\n",
        "else:\n",
        "    print(\"âœ… All videos have at least one cached feature file.\")\n"
      ],
      "metadata": {
        "id": "Y8Bi8y3araNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# SECTION 10 â€” Splits + classic models (VIDEO-level)\n",
        "# =========================\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "def stratified_group_shuffle_splits(labels, groups, test_size=0.30, n_splits=5, random_state=42):\n",
        "    \"\"\"\n",
        "    Group-aware train/test splits with approximate class balance.\n",
        "    IMPORTANT: groups should be unique per sample (use video_id) to avoid leakage.\n",
        "    \"\"\"\n",
        "    labels = np.asarray(labels)\n",
        "    groups = np.asarray(groups)\n",
        "    idx = np.arange(len(labels))\n",
        "\n",
        "    # Safety: avoid group leakage\n",
        "    assert len(np.unique(groups)) == len(groups), (\n",
        "        \"Group leakage risk: groups must be unique per sample. Use video_id as groups.\"\n",
        "    )\n",
        "\n",
        "    cls0 = idx[labels == 0]\n",
        "    cls1 = idx[labels == 1]\n",
        "\n",
        "    for k in range(n_splits):\n",
        "        rs = random_state + k\n",
        "        gss0 = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=rs)\n",
        "        gss1 = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=rs)\n",
        "\n",
        "        tr0, te0 = next(gss0.split(cls0, groups=groups[cls0]))\n",
        "        tr1, te1 = next(gss1.split(cls1, groups=groups[cls1]))\n",
        "\n",
        "        train_idx = np.concatenate([cls0[tr0], cls1[tr1]])\n",
        "        test_idx  = np.concatenate([cls0[te0], cls1[te1]])\n",
        "\n",
        "        yield np.sort(train_idx), np.sort(test_idx)\n",
        "\n",
        "def get_models_pipelines(seed=42):\n",
        "    base = [(\"scaler\", StandardScaler())]\n",
        "    return {\n",
        "        \"Random Forest\": Pipeline(base + [(\"clf\", RandomForestClassifier(\n",
        "            n_estimators=200, random_state=seed, n_jobs=-1\n",
        "        ))]),\n",
        "        \"SVM\": Pipeline(base + [(\"clf\", SVC(\n",
        "            probability=True, random_state=seed\n",
        "        ))]),\n",
        "        \"KNN\": Pipeline(base + [(\"clf\", KNeighborsClassifier(\n",
        "            n_neighbors=5\n",
        "        ))]),\n",
        "        \"Logistic Regression\": Pipeline(base + [(\"clf\", LogisticRegression(\n",
        "            max_iter=2000, random_state=seed\n",
        "        ))]),\n",
        "        \"XGBoost\": Pipeline(base + [(\"clf\", XGBClassifier(\n",
        "            n_estimators=300,\n",
        "            eval_metric=\"logloss\",\n",
        "            random_state=seed,\n",
        "            n_jobs=-1\n",
        "        ))]),\n",
        "    }\n",
        "\n",
        "def eval_classic_once(pooled, labels, train_idx, test_idx, seed=42):\n",
        "    \"\"\"\n",
        "    Train/evaluate classic models on ONE split.\n",
        "    Metrics are VIDEO-level (one sample per video).\n",
        "    \"\"\"\n",
        "    X_train, X_test = pooled[train_idx], pooled[test_idx]\n",
        "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
        "\n",
        "    results = {}\n",
        "    for name, pipe in get_models_pipelines(seed).items():\n",
        "        pipe.fit(X_train, y_train)\n",
        "        y_pred = pipe.predict(X_test)\n",
        "\n",
        "        # IMPORTANT: use the PIPELINE for proba/decision (includes scaler)\n",
        "        if hasattr(pipe, \"predict_proba\"):\n",
        "            y_prob = pipe.predict_proba(X_test)[:, 1]\n",
        "        elif hasattr(pipe, \"decision_function\"):\n",
        "            df = pipe.decision_function(X_test)\n",
        "            y_prob = (df - df.min()) / (df.max() - df.min() + 1e-12)\n",
        "        else:\n",
        "            y_prob = y_pred.astype(float)\n",
        "\n",
        "        acc = float(accuracy_score(y_test, y_pred))\n",
        "        f1  = float(f1_score(y_test, y_pred))\n",
        "        auc = float(\"nan\") if len(np.unique(y_test)) < 2 else float(roc_auc_score(y_test, y_prob))\n",
        "\n",
        "        results[name] = {\"accuracy\": acc, \"f1\": f1, \"auc\": auc}\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "U-OBSOlhqY2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# SECTION 11 â€” Run all experiments (5Ã— repeats, 70/30) â€” SAFE\n",
        "# =========================\n",
        "import os, json, glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "EXPERIMENTS = [\n",
        "    {\"name\":\"baseline\",         \"context\":False, \"aug\":False, \"mmd\":False, \"attention\":False},\n",
        "    {\"name\":\"context\",          \"context\":True,  \"aug\":False, \"mmd\":False, \"attention\":False},\n",
        "    {\"name\":\"aug\",              \"context\":False, \"aug\":True,  \"mmd\":False, \"attention\":False},\n",
        "    {\"name\":\"context_aug_mmd\",  \"context\":True,  \"aug\":True,  \"mmd\":True,  \"attention\":False},\n",
        "    {\"name\":\"attention_mil\",    \"context\":False, \"aug\":False, \"mmd\":False, \"attention\":True},\n",
        "]\n",
        "\n",
        "def export_mean_std(all_runs, exp_name, out_dir):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    models = sorted({m for r in all_runs for m in r.keys()})\n",
        "    rows = []\n",
        "\n",
        "    for m in models:\n",
        "        accs = [r[m][\"accuracy\"] for r in all_runs if m in r]\n",
        "        f1s  = [r[m][\"f1\"] for r in all_runs if m in r]\n",
        "        aucs = [r[m][\"auc\"] for r in all_runs if m in r and not np.isnan(r[m][\"auc\"])]\n",
        "\n",
        "        mu = lambda xs: float(np.mean(xs)) if xs else float(\"nan\")\n",
        "        sd = lambda xs: float(np.std(xs, ddof=1)) if len(xs) > 1 else 0.0\n",
        "\n",
        "        rows.append({\n",
        "            \"Model\": m,\n",
        "            \"Accuracy_mean\": mu(accs), \"Accuracy_std\": sd(accs),\n",
        "            \"F1_mean\":       mu(f1s),  \"F1_std\":       sd(f1s),\n",
        "            \"AUC_mean\":      mu(aucs), \"AUC_std\":      sd(aucs),\n",
        "            \"Runs\": len(accs)\n",
        "        })\n",
        "\n",
        "    out_csv = os.path.join(out_dir, f\"summary_{exp_name}_mean_std.csv\")\n",
        "    pd.DataFrame(rows).to_csv(out_csv, index=False)\n",
        "    print(f\"âœ… saved summary: {out_csv}\")\n",
        "\n",
        "def run_all_experiments(frames_df: pd.DataFrame, meta_df: pd.DataFrame, n_runs=5, seed=42):\n",
        "    \"\"\"\n",
        "    VIDEO-level evaluation:\n",
        "      - classic models on mean-pooled video embeddings\n",
        "      - attention MIL produces one score per video (not frame-level)\n",
        "    \"\"\"\n",
        "    assert \"video_id\" in frames_df.columns and \"cls\" in frames_df.columns, \"frames_df must have ['video_id','cls']\"\n",
        "    assert \"video_id\" in meta_df.columns and \"label\" in meta_df.columns, \"meta_df must have ['video_id','label']\"\n",
        "\n",
        "    # groups MUST be unique per sample (video_id)\n",
        "    groups = frames_df[\"video_id\"].astype(str).values\n",
        "    assert len(np.unique(groups)) == len(groups), \"Group leakage risk: frames_df video_id must be unique per row.\"\n",
        "\n",
        "    # Build labels safely (single index)\n",
        "    meta_idx = meta_df.set_index(\"video_id\")[\"label\"]\n",
        "    labels = meta_idx.reindex(frames_df[\"video_id\"]).astype(\"float\").values\n",
        "    assert not np.isnan(labels).any(), \"Some video_ids in frames_df are missing in meta_df.\"\n",
        "    labels = labels.astype(np.int64)\n",
        "\n",
        "    for exp in EXPERIMENTS:\n",
        "        name = exp[\"name\"]\n",
        "        print(f\"\\n========== EXPERIMENT: {name} ==========\")\n",
        "\n",
        "        exp_root = os.path.join(RESULTS_DIR, name)\n",
        "        os.makedirs(exp_root, exist_ok=True)\n",
        "\n",
        "        # Save config for documentation\n",
        "        with open(os.path.join(exp_root, \"config.json\"), \"w\") as f:\n",
        "            json.dump({\n",
        "                \"experiment\": name,\n",
        "                \"n_runs\": n_runs,\n",
        "                \"test_size\": 0.30,\n",
        "                \"seed\": seed,\n",
        "                \"context\": exp[\"context\"],\n",
        "                \"aug_train_only\": exp[\"aug\"],\n",
        "                \"attention\": exp[\"attention\"],\n",
        "                \"note\": \"VIDEO-level evaluation (not frame-level AUC).\"\n",
        "            }, f, indent=2)\n",
        "\n",
        "        all_runs = []\n",
        "\n",
        "        for run_id, (tr_idx, te_idx) in enumerate(\n",
        "            stratified_group_shuffle_splits(labels, groups, test_size=0.30, n_splits=n_runs, random_state=seed)\n",
        "        ):\n",
        "            run_dir = os.path.join(exp_root, f\"run_{run_id}\")\n",
        "            os.makedirs(run_dir, exist_ok=True)\n",
        "\n",
        "            train_vids = frames_df.iloc[tr_idx][\"video_id\"].astype(str).tolist()\n",
        "            test_vids  = frames_df.iloc[te_idx][\"video_id\"].astype(str).tolist()\n",
        "\n",
        "            pd.DataFrame({\"video_id\": train_vids, \"split\": \"train\"}).to_csv(os.path.join(run_dir, \"split_train.csv\"), index=False)\n",
        "            pd.DataFrame({\"video_id\": test_vids,  \"split\": \"test\"} ).to_csv(os.path.join(run_dir, \"split_test.csv\"),  index=False)\n",
        "\n",
        "            _overlap = set(train_vids).intersection(set(test_vids))\n",
        "            assert not _overlap, f\"Leak: overlap between splits: {len(_overlap)} vids\"\n",
        "\n",
        "            train_ids = set(train_vids)\n",
        "\n",
        "            # Build / load feature cache (AUG only for train videos if enabled)\n",
        "            _ = build_feature_cache_for_split(\n",
        "                frames_df=frames_df,\n",
        "                add_context=exp[\"context\"],\n",
        "                train_only_aug=exp[\"aug\"],\n",
        "                train_video_ids=train_ids,\n",
        "                run_id=run_id\n",
        "            )\n",
        "\n",
        "            # Load bags + pooled\n",
        "            bags, y, vids, pooled = load_bags_from_cache(\n",
        "                frames_df=frames_df,\n",
        "                add_context=exp[\"context\"],\n",
        "                train_only_aug=exp[\"aug\"],\n",
        "                train_video_ids=train_ids,\n",
        "                run_id=run_id\n",
        "            )\n",
        "\n",
        "            vid2idx = {v: i for i, v in enumerate(vids)}\n",
        "            tr = np.array([vid2idx[v] for v in train_vids if v in vid2idx], dtype=int)\n",
        "            te = np.array([vid2idx[v] for v in test_vids  if v in vid2idx], dtype=int)\n",
        "\n",
        "            # Guard: ensure split still has samples\n",
        "            if len(tr) < 2 or len(te) < 2:\n",
        "                print(f\"[WARN] run {run_id}: too few cached samples (train={len(tr)}, test={len(te)}). Skipping.\")\n",
        "                continue\n",
        "\n",
        "            # Audit: no augmentation on test\n",
        "            audit_no_aug_on_test(te, vids, exp[\"context\"], exp[\"aug\"], train_ids, run_id)\n",
        "\n",
        "            # Run evaluation\n",
        "            if exp[\"attention\"]:\n",
        "                res = evaluate_attention_mil_once(\n",
        "                    train_bags=[bags[i] for i in tr], train_y=y[tr],\n",
        "                    test_bags=[bags[i] for i in te],  test_y=y[te],\n",
        "                    epochs=5, lr=1e-3, batch_size=1, seed=seed+run_id, device=DEVICE\n",
        "                )\n",
        "                all_runs.append({\"Attention-MIL\": {\"accuracy\": res[\"accuracy\"], \"f1\": res[\"f1\"], \"auc\": res[\"auc\"]}})\n",
        "            else:\n",
        "                res = eval_classic_once(pooled, y, tr, te, seed+run_id)\n",
        "                all_runs.append(res)\n",
        "\n",
        "            # Optional: MMD logging (diagnostic only)\n",
        "            if exp[\"mmd\"]:\n",
        "                X0 = pooled[y == 0]\n",
        "                X1 = pooled[y == 1]\n",
        "                if len(X0) > 1 and len(X1) > 1:\n",
        "                    from sklearn.metrics import pairwise_distances\n",
        "                    from sklearn.metrics.pairwise import rbf_kernel\n",
        "\n",
        "                    D = pairwise_distances(np.vstack([X0, X1]))\n",
        "                    med = np.median(D[D > 0])\n",
        "                    gamma = 1.0 / (2.0 * (med**2 + 1e-12))\n",
        "\n",
        "                    mmd_val = (\n",
        "                        rbf_kernel(X0, X0, gamma=gamma).mean() +\n",
        "                        rbf_kernel(X1, X1, gamma=gamma).mean() -\n",
        "                        2.0 * rbf_kernel(X0, X1, gamma=gamma).mean()\n",
        "                    )\n",
        "                    with open(os.path.join(run_dir, \"mmd.txt\"), \"w\") as f:\n",
        "                        f.write(f\"MMD: {float(mmd_val):.6f}\\n\")\n",
        "\n",
        "        if not all_runs:\n",
        "            print(f\"[WARN] No successful runs for experiment '{name}'. Check frame extraction / feature cache.\")\n",
        "            continue\n",
        "\n",
        "        export_mean_std(all_runs, name, exp_root)\n"
      ],
      "metadata": {
        "id": "WCFdmvYXqd-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert 'frames_df' in globals() and not frames_df.empty\n",
        "assert 'meta' in globals() and not meta.empty\n",
        "\n",
        "# Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„ Ù„ÙƒÙ„ Ø§Ù„ØªØ¬Ø§Ø±Ø¨ Ù…Ø¹ 5 ØªÙƒØ±Ø§Ø±Ø§Øª\n",
        "run_all_experiments(frames_df=frames_df, meta_df=meta, n_runs=5, seed=42)\n"
      ],
      "metadata": {
        "id": "XkJIdR-or-QK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ù‚ÙŠØ§Ø³ RF/SVM/KNN/LR/XGB Ø¹Ù„Ù‰ Ù†ÙØ³ Ø§Ù„ØªÙ‚Ø³ÙŠÙ…Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ attention_mil (SAFE)\n",
        "import os, glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.base import clone\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "assert \"RESULTS_DIR\" in globals() and \"FEATURES_DIR\" in globals(), \"RESULTS_DIR/FEATURES_DIR ØºÙŠØ± Ù…Ø¹Ø±Ù‘ÙÙŠÙ†\"\n",
        "assert \"frames_df\" in globals() and not frames_df.empty, \"frames_df ØºÙŠØ± Ø¬Ø§Ù‡Ø²\"\n",
        "assert \"meta\" in globals() and not meta.empty, \"meta ØºÙŠØ± Ø¬Ø§Ù‡Ø²\"\n",
        "\n",
        "ATT_DIR = os.path.join(RESULTS_DIR, \"attention_mil\")\n",
        "assert os.path.isdir(ATT_DIR), f\"attention_mil folder not found: {ATT_DIR}\"\n",
        "\n",
        "# Ù†Ø¨Ù†ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒÙ„Ø§Ø³ÙŠÙƒÙŠØ© (mean-pooled) Ù…Ù† Ù†ÙØ³ ÙƒØ§Ø´ base_noaug/run0 (Ù„Ø£Ù† attention_mil Ø¹Ù†Ø¯Ùƒ Ø¨Ø¯ÙˆÙ† aug ÙˆØ¨Ø¯ÙˆÙ† context)\n",
        "X, y, vids = [], [], []\n",
        "\n",
        "missing_npz = 0\n",
        "empty_feats = 0\n",
        "\n",
        "for _, r in frames_df.iterrows():\n",
        "    vid = str(r[\"video_id\"])\n",
        "    cls = str(r[\"cls\"])\n",
        "    p = os.path.join(FEATURES_DIR, \"base_noaug\", \"run0\", cls, f\"{vid}.npz\")\n",
        "\n",
        "    if not os.path.exists(p):\n",
        "        missing_npz += 1\n",
        "        continue\n",
        "\n",
        "    d = np.load(p, allow_pickle=True)\n",
        "    feats = d[\"features\"]\n",
        "\n",
        "    if feats.size == 0:\n",
        "        empty_feats += 1\n",
        "        continue\n",
        "\n",
        "    X.append(feats.mean(axis=0).astype(np.float32))\n",
        "\n",
        "    if \"label\" in d.files:\n",
        "        y.append(int(d[\"label\"]))\n",
        "    else:\n",
        "        cls_npz = d[\"cls\"].item() if hasattr(d[\"cls\"], \"item\") else str(d[\"cls\"])\n",
        "        y.append(0 if str(cls_npz).lower() == \"normal\" else 1)\n",
        "\n",
        "    vids.append(vid)\n",
        "\n",
        "X = np.asarray(X, dtype=np.float32)\n",
        "y = np.asarray(y, dtype=np.int64)\n",
        "vid2idx = {v: i for i, v in enumerate(vids)}\n",
        "\n",
        "print(f\"[INFO] pooled samples: {len(vids)} | missing_npz: {missing_npz} | empty_feats: {empty_feats}\")\n",
        "\n",
        "# Ù†Ù…Ø§Ø°Ø¬ (Ø³Ù†Ø³ØªØ®Ø¯Ù… clone Ù„ÙƒÙ„ run)\n",
        "base_models = {\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1),\n",
        "    \"SVM\": SVC(probability=True, random_state=42),\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=2000, random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(\n",
        "        random_state=42,\n",
        "        n_estimators=300,\n",
        "        n_jobs=-1,\n",
        "        eval_metric=\"logloss\"\n",
        "    ),\n",
        "}\n",
        "\n",
        "all_runs = {m: [] for m in base_models.keys()}\n",
        "\n",
        "# Ø§Ù…Ø´Ù Ø¹Ù„Ù‰ Ù†ÙØ³ Ø§Ù„Ù€ runs Ø§Ù„ØªÙŠ Ù…ÙˆÙ„Ø¯Ù‡Ø§ attention_mil\n",
        "run_dirs = sorted(glob.glob(os.path.join(ATT_DIR, \"run_*\")))\n",
        "assert len(run_dirs) > 0, f\"No run_* dirs found inside: {ATT_DIR}\"\n",
        "\n",
        "skipped_runs = 0\n",
        "\n",
        "for rdir in run_dirs:\n",
        "    tr_path = os.path.join(rdir, \"split_train.csv\")\n",
        "    te_path = os.path.join(rdir, \"split_test.csv\")\n",
        "    if not (os.path.exists(tr_path) and os.path.exists(te_path)):\n",
        "        skipped_runs += 1\n",
        "        continue\n",
        "\n",
        "    tr_vids = pd.read_csv(tr_path)[\"video_id\"].astype(str).tolist()\n",
        "    te_vids = pd.read_csv(te_path)[\"video_id\"].astype(str).tolist()\n",
        "\n",
        "    tr_idx = np.array([vid2idx[v] for v in tr_vids if v in vid2idx], dtype=int)\n",
        "    te_idx = np.array([vid2idx[v] for v in te_vids if v in vid2idx], dtype=int)\n",
        "\n",
        "    if len(tr_idx) < 2 or len(te_idx) < 2:\n",
        "        skipped_runs += 1\n",
        "        continue\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    Xtr = scaler.fit_transform(X[tr_idx])\n",
        "    Xte = scaler.transform(X[te_idx])\n",
        "    ytr, yte = y[tr_idx], y[te_idx]\n",
        "\n",
        "    for name, base_clf in base_models.items():\n",
        "        clf = clone(base_clf)  # Ù…Ù‡Ù…: Ù…ÙˆØ¯ÙŠÙ„ Ø¬Ø¯ÙŠØ¯ Ù„ÙƒÙ„ run\n",
        "        clf.fit(Xtr, ytr)\n",
        "        yp = clf.predict(Xte)\n",
        "\n",
        "        if hasattr(clf, \"predict_proba\"):\n",
        "            prob = clf.predict_proba(Xte)[:, 1]\n",
        "        elif hasattr(clf, \"decision_function\"):\n",
        "            s = clf.decision_function(Xte)\n",
        "            prob = (s - s.min()) / (s.max() - s.min() + 1e-12)\n",
        "        else:\n",
        "            prob = yp.astype(float)\n",
        "\n",
        "        acc = float(accuracy_score(yte, yp))\n",
        "        f1  = float(f1_score(yte, yp))\n",
        "        auc = float(\"nan\") if len(np.unique(yte)) < 2 else float(roc_auc_score(yte, prob))\n",
        "\n",
        "        all_runs[name].append({\"accuracy\": acc, \"f1\": f1, \"auc\": auc})\n",
        "\n",
        "print(f\"[INFO] skipped_runs: {skipped_runs} / {len(run_dirs)}\")\n",
        "\n",
        "# Ø§Ø­Ø³Ø¨ meanÂ±std Ù„ÙƒÙ„ Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ø­ÙØ¸ Ø¬Ø¯ÙˆÙ„ Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø¬Ø§Ù†Ø¨ attention_mil\n",
        "rows = []\n",
        "for name, runs in all_runs.items():\n",
        "    accs = [r[\"accuracy\"] for r in runs]\n",
        "    f1s  = [r[\"f1\"] for r in runs]\n",
        "    aucs = [r[\"auc\"] for r in runs if not np.isnan(r[\"auc\"])]\n",
        "\n",
        "    mu = lambda a: float(np.mean(a)) if len(a) else float(\"nan\")\n",
        "    sd = lambda a: float(np.std(a, ddof=1)) if len(a) > 1 else 0.0\n",
        "\n",
        "    rows.append({\n",
        "        \"Model\": name,\n",
        "        \"Accuracy_mean\": mu(accs), \"Accuracy_std\": sd(accs),\n",
        "        \"F1_mean\":       mu(f1s),  \"F1_std\":       sd(f1s),\n",
        "        \"AUC_mean\":      mu(aucs), \"AUC_std\":      sd(aucs),\n",
        "        \"Runs\": len(runs)\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows).sort_values(\"AUC_mean\", ascending=False)\n",
        "out_csv = os.path.join(ATT_DIR, \"summary_attention_vs_classic_5.csv\")\n",
        "df.to_csv(out_csv, index=False)\n",
        "print(\"âœ… saved:\", out_csv)\n",
        "display(df)\n"
      ],
      "metadata": {
        "id": "sWtDcjeMs0Ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Ø§Ø¬Ø¹Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ù…Ø±Ù†Ù‹Ø§ (SAFE) ----------\n",
        "import os, glob, zipfile\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "BASE_RESULTS = \"/content/results\"\n",
        "PLOTS_DIR = os.path.join(BASE_RESULTS, \"plots_summary\")\n",
        "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
        "\n",
        "def find_latest(pattern, exclude_dir=\"plots_summary\"):\n",
        "    \"\"\"ÙŠØ¨Ø­Ø« Ø¨Ø´ÙƒÙ„ recursive Ø¯Ø§Ø®Ù„ results/ ÙˆÙŠØ¹ÙŠØ¯ Ø£Ø­Ø¯Ø« Ù…Ù„Ù ÙŠØ·Ø§Ø¨Ù‚ Ø§Ù„Ù†Ù…Ø· (Ø­Ø³Ø¨ mtime).\"\"\"\n",
        "    matches = glob.glob(os.path.join(BASE_RESULTS, \"**\", pattern), recursive=True)\n",
        "    matches = [m for m in matches if exclude_dir not in m.replace(\"\\\\\", \"/\")]\n",
        "    if not matches:\n",
        "        raise FileNotFoundError(f\"Ù„Ù… Ø£Ø¬Ø¯ Ø£ÙŠ Ù…Ù„Ù ÙŠØ·Ø§Ø¨Ù‚ Ø§Ù„Ù†Ù…Ø·: {pattern}\")\n",
        "    matches.sort(key=lambda p: os.path.getmtime(p), reverse=True)\n",
        "    print(\"â†’ using latest:\", matches[0])\n",
        "    return matches[0]\n",
        "\n",
        "# Ø§Ø®ØªÙŽØ± Ø£Ø­Ø¯Ø« Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ù„Ø®ØµØ§Øª\n",
        "classic_path = find_latest(\"summary_attention_vs_classic_5*.csv\")\n",
        "attn_path    = find_latest(\"summary_attention_mil_mean_std*.csv\")\n",
        "\n",
        "df_classic = pd.read_csv(classic_path)\n",
        "df_attn    = pd.read_csv(attn_path)\n",
        "\n",
        "# Ø¶Ù…Ø§Ù† ÙˆØ¬ÙˆØ¯ Ø¹Ù…ÙˆØ¯ Model ÙÙŠ Ù…Ù„Ù Attention\n",
        "if \"Model\" not in df_attn.columns:\n",
        "    df_attn.insert(0, \"Model\", \"Attention-MIL\")\n",
        "\n",
        "# ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©\n",
        "needed = [\"Model\", \"Accuracy_mean\", \"F1_mean\", \"AUC_mean\",\n",
        "          \"Accuracy_std\", \"F1_std\", \"AUC_std\", \"Runs\"]\n",
        "\n",
        "for col in needed:\n",
        "    if col not in df_classic.columns:\n",
        "        df_classic[col] = pd.NA\n",
        "    if col not in df_attn.columns:\n",
        "        df_attn[col] = pd.NA\n",
        "\n",
        "df_all = pd.concat([df_classic[needed], df_attn[needed]], ignore_index=True)\n",
        "\n",
        "# ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ© (Ù„ØªÙØ§Ø¯ÙŠ Ù†ØµÙˆØµ Ø¯Ø§Ø®Ù„ CSV)\n",
        "for c in [\"Accuracy_mean\",\"F1_mean\",\"AUC_mean\",\"Accuracy_std\",\"F1_std\",\"AUC_std\",\"Runs\"]:\n",
        "    df_all[c] = pd.to_numeric(df_all[c], errors=\"coerce\")\n",
        "\n",
        "# Ø­ÙØ¸ Ø¬Ø¯ÙˆÙ„ Ù…Ù„Ø®Øµ Ù…ÙˆØ­Ø¯\n",
        "out_csv = os.path.join(PLOTS_DIR, \"All_Models_Summary.csv\")\n",
        "df_all.to_csv(out_csv, index=False)\n",
        "print(\"âœ… saved unified table:\", out_csv)\n",
        "\n",
        "# --------- Ø±Ø³ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© (Accuracy / F1 / AUC) ----------\n",
        "metrics = [\"Accuracy_mean\", \"F1_mean\", \"AUC_mean\"]\n",
        "for metric in metrics:\n",
        "    df_plot = df_all.dropna(subset=[metric]).copy()\n",
        "    if df_plot.empty:\n",
        "        print(f\"[WARN] Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø±Ø³Ù… {metric}\")\n",
        "        continue\n",
        "\n",
        "    # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø­Ø³Ø¨ Ø£ÙØ¶Ù„ Ù‚ÙŠÙ…Ø© ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù‚ÙŠØ§Ø³\n",
        "    order = df_plot.sort_values(metric, ascending=False)[\"Model\"].tolist()\n",
        "\n",
        "    plt.figure(figsize=(9,5))\n",
        "    sns.barplot(x=\"Model\", y=metric, data=df_plot, order=order)\n",
        "    plt.title(f\"{metric} Comparison Across Models (VIDEO-level)\")\n",
        "    plt.xticks(rotation=35, ha=\"right\")\n",
        "    plt.tight_layout()\n",
        "    out_png = os.path.join(PLOTS_DIR, f\"{metric}_comparison.png\")\n",
        "    plt.savefig(out_png, dpi=200)\n",
        "    plt.close()\n",
        "    print(\"âœ… saved:\", out_png)\n",
        "\n",
        "# --------- Ø¶ØºØ· ÙƒÙ„ Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª ÙˆØ§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ù…Ù„Ù ZIP ----------\n",
        "zip_path = \"/content/All_Results_and_Plots.zip\"\n",
        "with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
        "    # Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ù„Ø®ØµØ§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ©\n",
        "    zf.write(classic_path, os.path.relpath(classic_path, BASE_RESULTS))\n",
        "    zf.write(attn_path,    os.path.relpath(attn_path,    BASE_RESULTS))\n",
        "\n",
        "    # Ù…Ù„Ù Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ù…ÙˆØ­Ø¯\n",
        "    zf.write(out_csv, os.path.relpath(out_csv, BASE_RESULTS))\n",
        "\n",
        "    # Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª\n",
        "    for root, _, files in os.walk(PLOTS_DIR):\n",
        "        for f in files:\n",
        "            fp = os.path.join(root, f)\n",
        "            zf.write(fp, os.path.relpath(fp, BASE_RESULTS))\n",
        "\n",
        "print(\"âœ… Ø¬Ø§Ù‡Ø²:\", zip_path)\n"
      ],
      "metadata": {
        "id": "du6XoM5ptl7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/All_Results_and_Plots.zip\")\n"
      ],
      "metadata": {
        "id": "ZtOMXmI_t_ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# SECTION: Collect all experiments results + plots into one ZIP (SAFE + MEANINGFUL)\n",
        "# ===============================================\n",
        "import os, glob, zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "BASE_RESULTS = \"/content/results\"\n",
        "ALL_PLOTS_DIR = os.path.join(BASE_RESULTS, \"All_Experiments_Plots\")\n",
        "os.makedirs(ALL_PLOTS_DIR, exist_ok=True)\n",
        "\n",
        "# ---------- 1) Ø§Ø¬Ù…Ø¹ ÙÙ‚Ø· Ù…Ù„ÙØ§Øª summary Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„ØªØ¬Ø§Ø±Ø¨ (baseline/context/...) ----------\n",
        "# Ù†Ø³ØªØ«Ù†ÙŠ Ø£ÙŠ summary Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ù†ÙØ³Ù‡Ø§ Ù„ØªÙØ§Ø¯ÙŠ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø§Ù„ØªÙ‚Ø§Ø·\n",
        "summary_files = glob.glob(os.path.join(BASE_RESULTS, \"*\", \"summary_*_mean_std.csv\"))\n",
        "print(f\"ðŸ“‚ Found {len(summary_files)} per-experiment summary files\")\n",
        "\n",
        "dfs = []\n",
        "for f in summary_files:\n",
        "    exp_name = os.path.basename(os.path.dirname(f))  # Ø§Ø³Ù… Ø§Ù„ØªØ¬Ø±Ø¨Ø© = Ø§Ø³Ù… Ø§Ù„Ù…Ø¬Ù„Ø¯\n",
        "    df = pd.read_csv(f)\n",
        "    if \"Model\" not in df.columns:\n",
        "        # Ù„Ùˆ Ù„Ø³Ø¨Ø¨ Ù…Ø§ Ù…Ù„Ù Ù…Ù„Ø®Øµ Ù…Ø®ØªÙ„Ù\n",
        "        continue\n",
        "    df.insert(0, \"Experiment\", exp_name)\n",
        "    dfs.append(df)\n",
        "\n",
        "if not dfs:\n",
        "    raise FileNotFoundError(\"âš ï¸ Ù„Ù… Ø£Ø¬Ø¯ summary_*_mean_std.csv Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ØªØ¬Ø§Ø±Ø¨ Ù…Ø¨Ø§Ø´Ø±Ø©.\")\n",
        "\n",
        "df_all = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ©\n",
        "for c in [\"Accuracy_mean\",\"F1_mean\",\"AUC_mean\",\"Accuracy_std\",\"F1_std\",\"AUC_std\",\"Runs\"]:\n",
        "    if c in df_all.columns:\n",
        "        df_all[c] = pd.to_numeric(df_all[c], errors=\"coerce\")\n",
        "\n",
        "df_all_path = os.path.join(ALL_PLOTS_DIR, \"All_Experiments_Summary_RAW.csv\")\n",
        "df_all.to_csv(df_all_path, index=False)\n",
        "print(f\"âœ… RAW combined summary saved â†’ {df_all_path}\")\n",
        "\n",
        "# ---------- 2) Ø®ÙŠØ§Ø± A: Ø£ÙØ¶Ù„ Ù…ÙˆØ¯ÙŠÙ„ Ù„ÙƒÙ„ ØªØ¬Ø±Ø¨Ø© (Ø­Ø³Ø¨ AUC_mean) ----------\n",
        "best_per_exp = (\n",
        "    df_all.dropna(subset=[\"AUC_mean\"])\n",
        "         .sort_values([\"Experiment\",\"AUC_mean\"], ascending=[True, False])\n",
        "         .groupby(\"Experiment\", as_index=False)\n",
        "         .head(1)\n",
        "         .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "best_path = os.path.join(ALL_PLOTS_DIR, \"All_Experiments_BEST_Model.csv\")\n",
        "best_per_exp.to_csv(best_path, index=False)\n",
        "print(f\"âœ… BEST-per-experiment table saved â†’ {best_path}\")\n",
        "\n",
        "# ---------- 3) Ø®ÙŠØ§Ø± B: Ù…Ù‚Ø§Ø±Ù†Ø© Ø¹Ù„Ù‰ Ù…ÙˆØ¯ÙŠÙ„ Ù…Ø­Ø¯Ø¯ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) ----------\n",
        "TARGET_MODEL = None  # Ø¶Ø¹ Ù…Ø«Ù„Ø§Ù‹ \"Logistic Regression\" Ø£Ùˆ \"SVM\" Ø£Ùˆ Ø§ØªØ±ÙƒÙ‡Ø§ None Ù„ØªØ¹Ø·ÙŠÙ„ Ù‡Ø°Ø§ Ø§Ù„Ø®ÙŠØ§Ø±\n",
        "\n",
        "if TARGET_MODEL is not None:\n",
        "    df_target = df_all[df_all[\"Model\"].astype(str) == TARGET_MODEL].copy()\n",
        "    target_path = os.path.join(ALL_PLOTS_DIR, f\"All_Experiments_{TARGET_MODEL.replace(' ','_')}.csv\")\n",
        "    df_target.to_csv(target_path, index=False)\n",
        "    print(f\"âœ… Target-model table saved â†’ {target_path}\")\n",
        "else:\n",
        "    df_target = pd.DataFrame()\n",
        "\n",
        "# ---------- 4) Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª: Ø§Ø±Ø³Ù… BEST-per-experiment (Ù…Ù†Ø·Ù‚ÙŠ) ----------\n",
        "metrics = [\"Accuracy_mean\", \"F1_mean\", \"AUC_mean\"]\n",
        "for metric in metrics:\n",
        "    if metric not in best_per_exp.columns:\n",
        "        continue\n",
        "    df_plot = best_per_exp.dropna(subset=[metric]).copy()\n",
        "    if df_plot.empty:\n",
        "        continue\n",
        "\n",
        "    # ØªØ±ØªÙŠØ¨ Ø§Ù„ØªØ¬Ø§Ø±Ø¨ ØªÙ†Ø§Ø²Ù„ÙŠÙ‹Ø§\n",
        "    order = df_plot.sort_values(metric, ascending=False)[\"Experiment\"].tolist()\n",
        "\n",
        "    plt.figure(figsize=(10,5))\n",
        "    sns.barplot(x=\"Experiment\", y=metric, data=df_plot, order=order)\n",
        "    plt.title(f\"{metric} â€” Best Model per Experiment (VIDEO-level)\")\n",
        "    plt.xticks(rotation=35, ha=\"right\")\n",
        "    plt.tight_layout()\n",
        "    out_png = os.path.join(ALL_PLOTS_DIR, f\"{metric}_BEST_per_experiment.png\")\n",
        "    plt.savefig(out_png, dpi=200)\n",
        "    plt.close()\n",
        "    print(\"ðŸ“Š saved:\", out_png)\n",
        "\n",
        "# (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) Ù„Ùˆ Ø§Ø®ØªØ±Øª TARGET_MODEL Ø§Ø±Ø³Ù…Ù‡ ÙƒØ°Ù„Ùƒ\n",
        "if not df_target.empty:\n",
        "    for metric in metrics:\n",
        "        df_plot = df_target.dropna(subset=[metric]).copy()\n",
        "        if df_plot.empty:\n",
        "            continue\n",
        "        order = df_plot.sort_values(metric, ascending=False)[\"Experiment\"].tolist()\n",
        "        plt.figure(figsize=(10,5))\n",
        "        sns.barplot(x=\"Experiment\", y=metric, data=df_plot, order=order)\n",
        "        plt.title(f\"{metric} â€” {TARGET_MODEL} Across Experiments (VIDEO-level)\")\n",
        "        plt.xticks(rotation=35, ha=\"right\")\n",
        "        plt.tight_layout()\n",
        "        out_png = os.path.join(ALL_PLOTS_DIR, f\"{metric}_{TARGET_MODEL.replace(' ','_')}_per_experiment.png\")\n",
        "        plt.savefig(out_png, dpi=200)\n",
        "        plt.close()\n",
        "        print(\"ðŸ“Š saved:\", out_png)\n",
        "\n",
        "# ---------- 5) ZIP: Ø§Ø¶Ù ÙƒÙ„ CSV/PNG/TXT Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ù†ÙŠØ© ----------\n",
        "zip_path = \"/content/All_Experiments_Results_and_Plots.zip\"\n",
        "with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
        "    for root, _, files in os.walk(BASE_RESULTS):\n",
        "        for file in files:\n",
        "            if file.endswith((\".csv\", \".png\", \".txt\")):\n",
        "                fpath = os.path.join(root, file)\n",
        "                zipf.write(fpath, os.path.relpath(fpath, BASE_RESULTS))\n",
        "\n",
        "print(f\"âœ… ÙƒÙ„ Ø§Ù„ØªØ¬Ø§Ø±Ø¨ Ù…Ø­ÙÙˆØ¸Ø© ÙˆÙ…Ø¶ØºÙˆØ·Ø© Ù‡Ù†Ø§:\\n{zip_path}\")\n"
      ],
      "metadata": {
        "id": "QqKr3BsJvFCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/All_Experiments_Results_and_Plots.zip\")\n"
      ],
      "metadata": {
        "id": "NBr9B0kFvVPT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}